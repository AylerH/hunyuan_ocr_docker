name: hunyuan_ocr_vllm

services:
  vllm:
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [ gpu ]
              driver: nvidia
              count: all
    image: valdanito/vllm:hunyun_ocr_20251126
    ipc: host
    volumes:
      - /storage-800GB/models:/storage-800GB/models
    entrypoint: python3
    command: -m vllm.entrypoints.openai.api_server --port=5000 --host=0.0.0.0 ${VLLM_ARGS}
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - LD_LIBRARY_PATH=/usr/local/cuda-12.9/compat:$$LD_LIBRARY_PATH
    ports:
        - 10003:5000
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://0.0.0.0:5000/v1/models" ]
      interval: 30s
      timeout: 5s
      retries: 20
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

